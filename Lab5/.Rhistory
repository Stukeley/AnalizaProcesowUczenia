2+@
2+2
# Autor: Rafal Klinowski, wariant: 1.
setwd('C:\\Users\\klino\\Pulpit\\Studia magisterskie\\APU\\Lab4')
# Zaladowanie danych o smartfonach (z lab1).
smartfony <- read.csv('smartfony.csv')
# Instalacja pakietu C50.
install.packages("C50")
library(C50)
# Konwersja wyjscia z drzewa (ocen klientow) na typ factor.
smartfony$oceny_klientow <- as.factor(smartfony$oceny_klientow)
# Stworzenie drzewa - prognozujemy oceny na podstawie innych wartosci.
tree <- C5.0(smartfony[, c('pamiec_ram', 'pamiec_wbudowana', 'aparat_foto', 'cena')],
smartfony[, 'oceny_klientow'])
# Wizualizacja drzewa.
plot(tree)
# Dane o drzewie.
summary(tree)
# -----------------------------
# Powtorzenie powyzszego z podzialem na zbior treningowy i testowy.
# W celu ewaluacji drzewa.
smartfony_train <- smartfony[1:12,]
smartfony_test <- smartfony[13:15,]
vars <- c('pamiec_ram', 'pamiec_wbudowana', 'aparat_foto', 'cena')
tree <- C5.0(x=smartfony_train[, vars],
y=smartfony_train$oceny_klientow)
summary(tree)
plot(tree)
# Predykcja dla danych testowych.
predict(tree, newdata = smartfony_test[, vars], type="prob")
setwd("C:\\Users\\klino\\Pulpit\\Studia magisterskie\\APU\\Lab2")
# Autor: Rafal Klinowski, wariant 1.
setwd("C:\\Users\\klino\\Pulpit\\Studia magisterskie\\APU\\Lab2")
# Zaladowanie danych
smartfony <- read.csv(file='smartfony.csv')
smartfony
# AHP z GitHuba
install.packages("devtools")
install.packages("githubinstall")
devtools::install_github("gluc/ahp", build_vignettes = TRUE)
library(ahp)
# Stworzenie drugiego datasetu z uwzglednieniem tylko istotnych parametrow
# Istotne parametry: wyswietlacz, pamiec RAM, pamiec wbudowana, aparat foto, cena.
smartfony_reduced <- smartfony[, c("nazwy", "pamiec_ram", "pamiec_wbudowana",
"aparat_foto", "cena")]
write.csv(smartfony_reduced, file='smartfony_reduced.csv')
# Zaladowanie przygotowanego pliku zawierajacego AHP
file.show("plik.ahp")
Load("plik.ahp")
# Instalacja mlr
install.packages("mlr")
library(mlr)
# Zadanie 1.
# Dataset: iris
library(datasets)
datasets?
?datasets
library(help="datasets")
data(iris)
# Instalacja mlr
install.packages("mlr")
install.packages("mlr")
library(mlr)
# Zadanie 1.
# Dataset: iris
library(datasets)
data(iris)
force(iris)
View(iris)
iris_task <- makeClassifTask(data = iris, target = "Species")
iris_split <- sample.split(iris$Species, SplitRatio = 0.7)
iris_task <- makeClassifTask(data = iris, target = "Species")
indices <- sample(1:nrow(iris), size = nrow(iris), replace = FALSE)
# Define the ratio for splitting (e.g., 70% for training, 30% for testing)
train_ratio <- 0.7
train_size <- floor(train_ratio * nrow(iris))
# Split the dataset into training and test sets
train_data <- iris[indices[1:train_size], ]
test_data <- iris[indices[(train_size + 1):nrow(iris)], ]
learner <- makeLearner("classif.randomForest")
model <- train(learner, iris_task, subset = train_data)
# Jakie sa dostepne learnery
levels(factor(listLearners()$type))
learner <- makeLearner("classif")
learner <- makeLearner("C50", type="classif")
learner <- makeLearner("classif.C50")
model <- train(learner, iris_task, subset = train_data)
model <- train(learner, iris_task)
predictions <- predict(model, newdata = test_data)
performance <- performance(predictions, measures = list(acc))
print(performance)
summary(model)
?rpart
# Wykres
rpart.plot(model$learner.model, roundint=FALSE, varlen=3, type=3, clip.right.labs=FALSE,
yesno=2)
# Wykres
library(rpart)
rpart.plot(model$learner.model, roundint=FALSE, varlen=3, type=3, clip.right.labs=FALSE,
yesno=2)
# Wykres
library(rpart.plot)
# Wykres
install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(model$learner.model, roundint=FALSE, varlen=3, type=3, clip.right.labs=FALSE,
yesno=2)
getLearnerModel(dtree_train)
getLearnerModel(model)
rpart.plot(model$learner.model, roundint=FALSE, varlen=3, type=3, clip.right.labs=FALSE,
yesno=2)
# [1] "classif"    "cluster"    "multilabel" "regr"       "surv"
levels(factor(listLearners()$type))
rpart.plot(model$learner.model)
# Wykres
plot(model)
# Wykres
plot(model$learner.model)
# Utworzenie learnera i trening
learner <- makeLearner("classif.rpart")
model <- train(learner, iris_task)
# Ocena jakosci modelu
predictions <- predict(model, newdata = test_data)
performance <- performance(predictions, measures = list(acc))
print(performance)
summary(model)
# Wykres
library(rpart.plot)
rpart.plot(getLearnerModel(model))
# Reguły klasyfikacyjne
ruleModel <- C5.0(Species ~ ., data=train_data, rules=TRUE)
ruleModel
summary(ruleModel)
# Zadanie 2.
smartfony <- read.csv('smartfony.csv')
smartfony_reduced <- smartfony[,
c('pamiec_ram', 'pamiec_wbudowana', 'aparat_foto', 'cena', 'oceny_klientow')]
iris_task <- makeClassifTask(data = smartfony_reduced, target = "oceny_klientow")
print(performance)
smartfony_task <- makeClassifTask(data = smartfony_reduced, target = "oceny_klientow")
lrns <- makeLearners(c("lda","rpart", "C50","rFerns",
"randomForestSRC"), type = "classif")
install.packages("rFerns")
lrns <- makeLearners(c("lda","rpart", "C50","rFerns",
"randomForestSRC"), type = "classif")
lrns <- makeLearners(c("lda","rpart", "C50","rFerns",
"randomForest"), type = "classif")
install.packages("randomForest")
lrns <- makeLearners(c("lda","rpart", "C50","rFerns",
"randomForest"), type = "classif")
porownanie <- benchmark(learners = lrns,
tasks = task,
resampling = cv5)
porownanie <- benchmark(learners = lrns,
tasks = smartfony_task,
resampling = cv5)
plot(porownanie)
autoplot(porownanie)
library(mlrCPO)
install.packages("mlrCPO")
library(mlrCPO)
autoplot(porownanie)
View(porownanie)
View(porownanie)
# Wizualizacja oceny
learner <- c("lda", "rpart", "C50", "rFerns", "randomForest")
accuracy <- c(0.267, 0.2, 0.2, 0.867, 0.267)
data <- data.frame(learner, accuracy)
barplot(data$accuracy, names.arg = data$learner, ylim = c(0, 1), ylab = "Accuracy")
performance <- performance(smartfony_predictions, measures = list(acc))
# Utworzenie finalnego modelu
smartfony_task <- makeClassifTask(data = smartfony_reduced, target = "oceny_klientow")
smartfony_train <- smartfony_reduced[1:12, ]
smartfony_test <- smartfony_reduced[13:15, ]
smartfony_learner <- makeLearner("classif.rFerns")
smartfony_model <- train(smartfony_learner, smartfony_task)
smartfony_predictions <- predict(smartfony_model, newdata = smartfony_test)
performance <- performance(smartfony_predictions, measures = list(acc))
print(performance)
# Autor: Rafal Klinowski, wariant: 1.
setwd('C:\\Users\\klino\\Pulpit\\Studia magisterskie\\APU\\Lab5')
# Instalacja mlr
install.packages("mlr")
library(mlr)
# Zadanie 1.
# Dataset: iris
library(datasets)
# Zaladowanie danych 'iris'
data(iris)
# Utworzenie klasyfikatora na podstawie gatunku 'species'
iris_task <- makeClassifTask(data = iris, target = "Species")
# Podzial danych na set treningowy i testowy (70% / 30%)
indices <- sample(1:nrow(iris), size = nrow(iris), replace = FALSE)
train_ratio <- 0.7
train_size <- floor(train_ratio * nrow(iris))
train_data <- iris[indices[1:train_size], ]
test_data <- iris[indices[(train_size + 1):nrow(iris)], ]
# Jakie sa dostepne learnery
# [1] "classif"    "cluster"    "multilabel" "regr"       "surv"
levels(factor(listLearners()$type))
# Utworzenie learnera i trening
learner <- makeLearner("classif.rpart")
model <- train(learner, iris_task)
# Ocena jakosci modelu
predictions <- predict(model, newdata = test_data)
performance <- performance(predictions, measures = list(acc))
print(performance)
summary(model)
# Wykres
library(rpart.plot)
rpart.plot(getLearnerModel(model))
# Reguły klasyfikacyjne
ruleModel <- C5.0(Species ~ ., data=train_data, rules=TRUE)
ruleModel
summary(ruleModel)
# Zadanie 2.
smartfony <- read.csv('smartfony.csv')
smartfony_reduced <- smartfony[,
c('pamiec_ram', 'pamiec_wbudowana', 'aparat_foto', 'cena', 'oceny_klientow')]
# Utworzenie klasyfikatora
smartfony_task <- makeClassifTask(data = smartfony_reduced, target = "oceny_klientow")
# Stworzenie 5 learnerow
install.packages("rFerns")
install.packages("randomForest")
lrns <- makeLearners(c("lda","rpart", "C50","rFerns",
"randomForest"), type = "classif")
porownanie <- benchmark(learners = lrns,
tasks = smartfony_task,
resampling = cv5)
# Wizualizacja oceny
learner <- c("lda", "rpart", "C50", "rFerns", "randomForest")
accuracy <- c(0.267, 0.2, 0.2, 0.867, 0.267)
data <- data.frame(learner, accuracy)
barplot(data$accuracy, names.arg = data$learner, ylim = c(0, 1), ylab = "Accuracy")
# Utworzenie finalnego modelu
smartfony_task <- makeClassifTask(data = smartfony_reduced, target = "oceny_klientow")
smartfony_train <- smartfony_reduced[1:12, ]
smartfony_test <- smartfony_reduced[13:15, ]
smartfony_learner <- makeLearner("classif.rFerns")
smartfony_model <- train(smartfony_learner, smartfony_task)
smartfony_predictions <- predict(smartfony_model, newdata = smartfony_test)
performance <- performance(smartfony_predictions, measures = list(acc))
print(performance)
install.packages("mlr")
install.packages("randomForest")
install.packages("randomForest")
